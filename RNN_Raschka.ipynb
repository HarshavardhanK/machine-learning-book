{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshavardhanK/machine-learning-book/blob/main/RNN_Raschka.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lWq9-IjwPSN_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nmHoEXLuKZjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6185f7a8-e254-4b12-85ce-eccd54cd5f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install 'portalocker>=2.0.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQRRtP_2Pilb",
        "outputId": "4521c519-1915-499e-e10c-1b85a4d46526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7db8b4281290>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R1UhNe4FPtCi"
      },
      "outputs": [],
      "source": [
        "rnn_layer = nn.RNN(input_size=5, hidden_size=3, num_layers=1, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8F_ZbeCYP-Lr"
      },
      "outputs": [],
      "source": [
        "w_xh = rnn_layer.weight_ih_l0\n",
        "w_hh = rnn_layer.weight_hh_l0\n",
        "b_xh = rnn_layer.bias_ih_l0\n",
        "b_hh = rnn_layer.bias_hh_l0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmAOFg0bQSPx",
        "outputId": "d582c8e5-9f48-4c0e-8f0f-481eb6090d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w_xh shape:  torch.Size([3, 5])\n",
            "w_hh shape:  torch.Size([3, 3])\n",
            "b_xh shape:  torch.Size([3])\n",
            "b_hh shape:  torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "print(\"w_xh shape: \", w_xh.shape)\n",
        "print(\"w_hh shape: \", w_hh.shape)\n",
        "print(\"b_xh shape: \", b_xh.shape)\n",
        "print(\"b_hh shape: \", b_xh.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtI80Aj2QckF",
        "outputId": "e3564352-5e68-465b-d375-bea90f79c400"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x_seq = torch.tensor([[1.0] * 5, [2.0] * 5, [3.0] * 5, [4.0] * 5]).float()\n",
        "x_seq.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ja34xLUjWQd",
        "outputId": "0942cc90-c6fa-4ac6-8732-ff4ef90d2546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8190,  0.8263,  0.8389]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "output, hnn = rnn_layer(torch.reshape(x_seq, (1, 4, 5)))\n",
        "hnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxWjo7Dpjwo9",
        "outputId": "210dc8b5-6f97-466f-ff25-4b68ffd2de3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5])\n",
            "Time step {t} => \n",
            "   Input      [[1. 1. 1. 1. 1.]]\n",
            "W_xh shape:  torch.Size([3, 5])\n",
            "Transpose shape:  torch.Size([5, 3])\n",
            "ht shape:  torch.Size([1, 3])\n",
            "     Hidden      : [[-0.52682793  0.55840755  0.47656733]]\n",
            "   Output (manual)     [[-0.20985235 -0.00598161  0.6828735 ]]\n",
            "   RNN output          [[-0.20985247 -0.00598161  0.6828735 ]]\n",
            "torch.Size([1, 5])\n",
            "Time step {t} => \n",
            "   Input      [[2. 2. 2. 2. 2.]]\n",
            "W_xh shape:  torch.Size([3, 5])\n",
            "Transpose shape:  torch.Size([5, 3])\n",
            "ht shape:  torch.Size([1, 3])\n",
            "     Hidden      : [[-0.8686449   1.0891707   0.60896015]]\n",
            "   Output (manual)     [[-0.49751765  0.2645275   0.7016616 ]]\n",
            "   RNN output          [[-0.49751776  0.2645275   0.70166165]]\n",
            "torch.Size([1, 5])\n",
            "Time step {t} => \n",
            "   Input      [[3. 3. 3. 3. 3.]]\n",
            "W_xh shape:  torch.Size([3, 5])\n",
            "Transpose shape:  torch.Size([5, 3])\n",
            "ht shape:  torch.Size([1, 3])\n",
            "     Hidden      : [[-1.210462   1.6199336  0.741353 ]]\n",
            "   Output (manual)     [[-0.69121206  0.60507196  0.7903675 ]]\n",
            "   RNN output          [[-0.6912121   0.60507184  0.7903675 ]]\n",
            "torch.Size([1, 5])\n",
            "Time step {t} => \n",
            "   Input      [[4. 4. 4. 4. 4.]]\n",
            "W_xh shape:  torch.Size([3, 5])\n",
            "Transpose shape:  torch.Size([5, 3])\n",
            "ht shape:  torch.Size([1, 3])\n",
            "     Hidden      : [[-1.5522788   2.1506968   0.87374586]]\n",
            "   Output (manual)     [[-0.8189856   0.82625824  0.83885515]]\n",
            "   RNN output          [[-0.8189857   0.8262582   0.83885515]]\n"
          ]
        }
      ],
      "source": [
        "out_man = []\n",
        "\n",
        "for t in range(4):\n",
        "  xt = torch.reshape(x_seq[t], (1, 5))\n",
        "  print(xt.shape)\n",
        "  print(\"Time step {t} => \")\n",
        "  print('   Input     ', xt.numpy())\n",
        "  print('W_xh shape: ', w_xh.shape)\n",
        "  print(\"Transpose shape: \", torch.transpose(w_xh, 0, 1).shape)\n",
        "\n",
        "  ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
        "  print(\"ht shape: \", ht.shape)\n",
        "\n",
        "  print('     Hidden      :', ht.detach().numpy())\n",
        "\n",
        "  if t > 0:\n",
        "    prev_h = out_man[t - 1]\n",
        "\n",
        "  else:\n",
        "    prev_h = torch.zeros((ht.shape))\n",
        "\n",
        "\n",
        "  ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
        "\n",
        "  ot = torch.tanh(ot)\n",
        "  out_man.append(ot)\n",
        "\n",
        "  print(\"   Output (manual)    \", ot.detach().numpy())\n",
        "  print(\"   RNN output         \", output[:, t].detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "leDxCDpbkxi4"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torchtext.vocab import vocab\n",
        "from torch.utils.data.dataset import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MHgfb26CKHtQ"
      },
      "outputs": [],
      "source": [
        "train_dataset = IMDB(split='train')\n",
        "test_dataset = IMDB(split='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4NT4kSxKTmR",
        "outputId": "77633e7e-41a6-4fe1-b0a2-dd7e9efb0263"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7db8b4281290>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HTM-fF6gKOTZ"
      },
      "outputs": [],
      "source": [
        "train_dataset, validation_dataset = random_split(list(train_dataset), [20000, 5000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cBUbHIhIKtab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53757129-47bd-405d-d515-c523b5a7b4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab-size: 69023\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "token_counts = Counter()\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
        "        ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = text.split()\n",
        "    return tokenized\n",
        "\n",
        "for label, line in train_dataset:\n",
        "    tokens = tokenizer(line)\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "\n",
        "print('Vocab-size:', len(token_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXw7fSYeyXtX",
        "outputId": "6b5e5c77-894e-448d-83d2-54edb2e37641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 7, 35, 457]\n"
          ]
        }
      ],
      "source": [
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "\n",
        "vocab = vocab(ordered_dict)\n",
        "\n",
        "vocab.insert_token(\"<pad>\", 0)\n",
        "vocab.insert_token(\"<unk>\", 1)\n",
        "vocab.set_default_index(1)\n",
        "\n",
        "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dAZDThzKyXtX"
      },
      "outputs": [],
      "source": [
        "text_pipeline = lambda x : [vocab[token] for token in tokenizer(x)]\n",
        "label_pipeline = lambda x: 1. if x == \"pos\" else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YtlGJEYyXtX",
        "outputId": "b2eae28a-8f57-4570-d618-b40b5f94c301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(torch.device('cuda') if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "eKGET6tgyXtX"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "\n",
        "    for _label, _text in batch:\n",
        "\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text))\n",
        "\n",
        "        text_list.append(processed_text)\n",
        "        lengths.append(processed_text.size(0))\n",
        "\n",
        "    label_list = torch.tensor(label_list)\n",
        "    lengths = torch.tensor(lengths)\n",
        "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
        "\n",
        "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "n5zPAGH2yXtX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "KwAUJlx5yXtY"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_dataset, batch_size=32, collate_fn=collate_batch, shuffle=True)\n",
        "valid_dl = DataLoader(validation_dataset, batch_size=32, collate_fn=collate_batch, shuffle=False)\n",
        "test_dl = DataLoader(test_dataset, batch_size=32, collate_fn=collate_batch, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YRH5sn9yXtY",
        "outputId": "2aae87fa-18f7-4ec4-e2db-00dd3b4a9d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.1660, -1.0748,  1.3168, -0.6818],\n",
            "         [-1.1660, -1.0748,  1.3168, -0.6818],\n",
            "         [-1.1660, -1.0748,  1.3168, -0.6818],\n",
            "         [-1.1660, -1.0748,  1.3168, -0.6818]],\n",
            "\n",
            "        [[-1.1660, -1.0748,  1.3168, -0.6818],\n",
            "         [-1.1660, -1.0748,  1.3168, -0.6818],\n",
            "         [-1.1660, -1.0748,  1.3168, -0.6818],\n",
            "         [-1.1660, -1.0748,  1.3168, -0.6818]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "## Create dummy embeddings\n",
        "embed = nn.Embedding(num_embeddings=10, embedding_dim=4, padding_idx=0) #providing padding index will not affect the 0th index during gradient update\n",
        "text_encoded_input = torch.LongTensor([[1,1,1,1], [1,1,1,1]])\n",
        "print(embed(text_encoded_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "0Po6WwFhyXtY"
      },
      "outputs": [],
      "source": [
        "class Dummy_RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, hidden = self.rnn(x)\n",
        "        out = hidden[-1, :, :]\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQWAgN1kyXtY",
        "outputId": "a8d7792e-84f8-498b-d5fe-d11f169fa550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy_RNN(\n",
            "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = Dummy_RNN(64, 32)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0MVZI_qyXtY",
        "outputId": "49aca4f2-0ce5-4d90-f793-7bf6304d4d1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1765],\n",
              "        [-0.4967]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "model(torch.randn(2, 3, 64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzxV2A0DyXtY",
        "outputId": "7edc59bc-3c8a-4040-de03-4d47a6d1243b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n",
            "             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n",
            "           100,  1874,  1739,    25,     7, 34415,  3568,  1103,  7517,   787,\n",
            "             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n",
            "         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n",
            "          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n",
            "         42945,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n",
            "           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n",
            "          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n",
            "         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n",
            "          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n",
            "            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n",
            "           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n",
            "          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n",
            "           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n",
            "           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n",
            "            31,   189,  3506,   667,   163,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n",
            "           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n",
            "           182,    50,   150,    24,    85,     2,  4031,  5935,   107,    96,\n",
            "            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n",
            "          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n",
            "          6022,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n",
            "          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n",
            "          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n",
            "           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   10,   121,    24,    28,    98,    74,   589,     9,   149,     2,\n",
            "          7372,  3030, 14543,  1012,   520,     2,   985,  2327,     5, 16847,\n",
            "          5479,    19,    25,    67,    76,  3478,    38,     2,  7372,     3,\n",
            "            25,    67,    76,  2951,    34,    35, 10893,   155,   449, 29495,\n",
            "         23725,    10,    67,     2,   554,    12, 14543,    67,    91,     4,\n",
            "            50,    20,    19,     8,    67,    24,  4228,     2,  2142,    37,\n",
            "            33,  3478,    87,     3,  2564,   160,   155,    11,   634,   126,\n",
            "            24,   158,    72,   286,    13,   373,     2,  4804,    19,     2,\n",
            "          7372,  6794,     6,    30,   128,    73,    48,    10,   886,     8,\n",
            "            13,    24,     4,    85,    20,    19,     8,    13,    35,   218,\n",
            "             3,   428,   710,     2,   107,   936,     7,    54,    72,   223,\n",
            "             3,    10,    96,   122,     2,   103,    54,    72,    82,     2,\n",
            "           658,   202,     2,   106,   293,   103,     7,  1193,     3,  3031,\n",
            "           708,  5760,     3,  2918,  3991,   706,  3327,   349,   148,   286,\n",
            "            13,   139,     6,     2,  1501,   750,    29,  1407,    62,    65,\n",
            "          2612,    71,    40,    14,     4,   547,     9,    62,     8,  7943,\n",
            "            71,    14,     2,  5687,     5,  4868,  3111,     6,   205,     2,\n",
            "            18,    55,  2075,     3,   403,    12,  3111,   231,    45,     5,\n",
            "           271,     3,    68,  1400,     7,  9774,   932,    10,   102,     2,\n",
            "            20,   143,    28,    76,    55,  3810,     9,  2723,     5,    12,\n",
            "            10,   379,     2,  7372,    15,     4,    50,   710,     8,    13,\n",
            "            24,   887,    32,    31,    19,     8,    13,   428],\n",
            "        [18923,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n",
            "           502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n",
            "            90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n",
            "           847,    62,    77,   131,     9,     2,  1580,   338,     5, 18923,\n",
            "            32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n",
            "         10298,     2, 18924,   125,     9,   502,     3,   453,     4,  1852,\n",
            "           630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n",
            "         18923,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n",
            "           214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n",
            "           597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n",
            "           289, 10038,     5,     2,    20,    26,   841,  1392,    62,   130,\n",
            "           111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n",
            "            66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n",
            "            78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n",
            "          3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
            "       device='cuda:0')\n",
            "tensor([0, 0, 0, 0], device='cuda:0')\n",
            "tensor([165,  86, 218, 145], device='cuda:0')\n",
            "torch.Size([4, 218])\n"
          ]
        }
      ],
      "source": [
        "## Take a small batch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
        "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
        "print(text_batch)\n",
        "print(label_batch)\n",
        "print(length_batch)\n",
        "print(text_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "t9nZsAoRyXtY"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, fc_hidden_size, rnn_hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.LSTM = nn.LSTM(embedding_dim, rnn_hidden_size, batch_first=True)\n",
        "\n",
        "        self.fully_connected1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
        "        self.Relu = nn.ReLU()\n",
        "\n",
        "        self.fully_connected2 = nn.Linear(fc_hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        out = self.embedding(text)\n",
        "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
        "\n",
        "        out, (hidden, cell) = self.LSTM(out)\n",
        "        out = hidden[-1, :, :]\n",
        "\n",
        "        out = self.fully_connected1(out)\n",
        "        out = self.Relu(out)\n",
        "\n",
        "        out = self.fully_connected2(out)\n",
        "        out = self.sigmoid(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPQDN3_RyXtY",
        "outputId": "dd76c5f8-259c-43f6-bc72-84f08a8aeb8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7db8b4281290>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "embed_dim = 20\n",
        "rnn_hidden_size = 64\n",
        "fc_hidden_size = 64\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "PzO_lRKByXtZ"
      },
      "outputs": [],
      "source": [
        "model = RNN(vocab_size=vocab_size, embedding_dim=embed_dim, rnn_hidden_size=rnn_hidden_size, fc_hidden_size=fc_hidden_size)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIP1F3UayXtZ",
        "outputId": "8a11a44a-2bba-4ab6-9bab-e55db9b7cad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (embedding): Embedding(69025, 20, padding_idx=0)\n",
            "  (LSTM): LSTM(20, 64, batch_first=True)\n",
            "  (fully_connected1): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (Relu): ReLU()\n",
            "  (fully_connected2): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "py8dGZryyXtZ"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.001)\n",
        "loss_fn = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "bVyWzynOyXtZ"
      },
      "outputs": [],
      "source": [
        "def train(dataloader):\n",
        "    model.train()\n",
        "\n",
        "    total_acc, total_loss = 0, 0\n",
        "\n",
        "    for text_batch, label_batch, length in dataloader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        label_batch = label_batch.to(torch.float32)\n",
        "        pred = model(text_batch, length)[:, 0]\n",
        "        loss = loss_fn(pred, label_batch)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
        "        total_loss += loss.item() * label_batch.size(0)\n",
        "\n",
        "        ln = len(dataloader.dataset)\n",
        "\n",
        "    return total_acc / ln, total_loss / ln\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "Okh4Vf0GyXtZ"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    total_acc, total_loss = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text_batch, label_batch, lengths in dataloader:\n",
        "            label_batch = label_batch.to(torch.float32)\n",
        "            pred = model(text_batch, lengths)[:, 0]\n",
        "            loss = loss_fn(pred, label_batch)\n",
        "\n",
        "            total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
        "            total_loss += loss.item() * label_batch.size(0)\n",
        "\n",
        "            ln = len(dataloader.dataset)\n",
        "\n",
        "    return total_acc / ln, total_loss / ln"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBDUp7hWyXtZ",
        "outputId": "89b40d93-b061-40d4-f047-c10c3427e0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 accuracy:  0.9987 val acc:  1.0000\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "torch.manual_seed(1)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    acc_train, loss_train = train(dataloader=train_dl)\n",
        "    acc_valid, loss_valid = evaluate(dataloader=valid_dl)\n",
        "\n",
        "    print(f'Epoch {epoch} accuracy: {acc_train: .4f} '\n",
        "          f'val acc: {acc_valid: .4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "kX2Q3GkRyXtZ",
        "outputId": "b99e4d78-85be-4690-b7f0-733060dcee1d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-66c602899dba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torchtext' is not defined"
          ]
        }
      ],
      "source": [
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN0nJDAAyXtZ"
      },
      "outputs": [],
      "source": [
        "import torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ieO6enVyXtZ",
        "outputId": "d71ddbda-073f-443f-ea73-f97700314bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this\n"
          ]
        }
      ],
      "source": [
        "from torchtext import __version__ as torchtext_version\n",
        "from pkg_resources import parse_version\n",
        "\n",
        "if parse_version(torchtext.__version__) > parse_version(\"0.10\"):\n",
        "    label_pipeline = lambda x: 1. if x == 2 else 0.         # 1 ~ negative, 2 ~ positive review\n",
        "    print('sup man')\n",
        "else:\n",
        "    label_pipeline = lambda x: 1. if x == 'pos' else 0.\n",
        "    print('this')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23OlPS70yXta"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}